# Criando Processos de Redund√¢ncia de Arquivos na Azure.


![Azure_Databricks01](https://github.com/user-attachments/assets/8ddea732-e045-4694-9207-87aeb9403938)

---

**DESCRI√á√ÉO:**

Neste projeto pr√°tico, o objetivo √© criar um processo completo de redund√¢ncia de arquivos utilizando recursos do Microsoft Azure. 

Atrav√©s do Azure Data Factory, voc√™ aprender√° a configurar uma infraestrutura necess√°ria, incluindo conex√µes com ambientes on-premises (via Integration Runtime), bancos de dados SQL (Azure e locais) e armazenamento em blob storage. 

Aprenda o passo a passo, como criar linked services, datasets e pipelines para mover dados de uma tabela SQL on-premises para o Azure Data Lake, convertendo as informa√ß√µes em arquivos .TXT organizados por camadas (como raw/bronze). 

O hands-on tamb√©m aborda valida√ß√£o, publica√ß√£o e execu√ß√£o dos pipelines, com an√°lise de performance e boas pr√°ticas de configura√ß√£o.



---


**Processo de Redund√¢ncia de Arquivos na Azure**

Este projeto demonstra como implementar um **processo de redund√¢ncia de arquivos** utilizando **Azure Data Factory**, **Self-hosted Integration Runtime**, **Azure Data Lake Storage Gen2** e **Databricks**.  

O objetivo √© copiar dados de um **SQL Server on-premises** para o **Data Lake**, convertendo-os em arquivos `.txt/.csv` organizados por camadas (`raw` e `bronze`), garantindo redund√¢ncia, escalabilidade e boas pr√°ticas de integra√ß√£o h√≠brida.

---

 **Objetivos do Projeto**
- Criar pipelines no **Azure Data Factory** para mover dados de SQL on-premises para o Data Lake.
  
- Configurar **Self-hosted Integration Runtime (IR)** para conectar ambientes locais ao Azure.
  
- Organizar dados em camadas (`raw` e `bronze`) para redund√¢ncia e governan√ßa.  
- Documentar e versionar todos os artefatos no GitHub.
  
- Demonstrar boas pr√°ticas de seguran√ßa, parametriza√ß√£o e monitoramento.  

---

 **Tecnologias Utilizadas**
 
- **Azure Data Factory (ADF)** ‚Üí Orquestra√ß√£o de pipelines.  
- **Self-hosted Integration Runtime (IR)** ‚Üí Conex√£o segura com SQL on-premises.  
- **Azure Data Lake Storage Gen2 (ADLS)** ‚Üí Armazenamento em camadas.  
- **Azure Key Vault** ‚Üí Gerenciamento seguro de segredos.  
- **Databricks** ‚Üí Processamento e promo√ß√£o de dados da camada `raw` para `bronze`.  
- **SQL Server** ‚Üí Base de dados on-premises.  
- **GitHub** ‚Üí Versionamento e documenta√ß√£o.  

---

## üìÇ Estrutura de Pastas e Arquivos 


<img width="805" height="1587" alt="Screenshot_20251111-165706" src="https://github.com/user-attachments/assets/e3d4e52f-41ab-41d3-9996-1bd4865d7def" />





---

## üìë Explica√ß√£o dos Arquivos

### üìÅ docs/
- **imagens/adf_linked_services.png** ‚Üí Print da configura√ß√£o dos Linked Services no ADF.  
- **imagens/adf_datasets.png** ‚Üí Print da configura√ß√£o dos Datasets no ADF.  
- **arquitetura_azure.png** ‚Üí Diagrama da arquitetura do projeto (ADF + IR + ADLS + Databricks).  
- **guia_instalacao_ir.md** ‚Üí Guia detalhado de instala√ß√£o e configura√ß√£o do Self-hosted IR.  

### üìÅ adf/linkedServices/
- **LS_SQL_OnPrem.json** ‚Üí Linked Service para conex√£o com SQL Server on-premises via IR.  
- **LS_ADLS.json** ‚Üí Linked Service para conex√£o com o Data Lake Storage Gen2.  
- **LS_KeyVault.json** ‚Üí Linked Service para acessar segredos armazenados no Azure Key Vault.  

### üìÅ adf/datasets/
- **DS_SQL_OnPrem_<Tabela>.json** ‚Üí Dataset de origem (tabela SQL on-premises).  
- **DS_ADLS_RAW_TXT.json** ‚Üí Dataset de destino na camada `raw` (arquivos TXT/CSV).  
- **DS_ADLS_BRONZE_TXT.json** ‚Üí Dataset de destino na camada `bronze`.  

### üìÅ adf/pipelines/
- **pl_redundancia_sql_to_datalake.json** ‚Üí Pipeline principal que copia dados do SQL para o Data Lake (`raw` ‚Üí `bronze`).  

### üìÅ adf/triggers/
- **tr_daily_0200_brt.json** ‚Üí Trigger de execu√ß√£o di√°ria √†s 02:00 BRT.  

### üìÅ databricks/
- **notebooks/bronze_promote_<tabela>.ipynb** ‚Üí Notebook Databricks para promover dados da camada `raw` para `bronze`.  
- **configs/cluster_config.json** ‚Üí Configura√ß√£o de cluster Databricks (n√≥s, vers√£o Spark, auto-termina√ß√£o).  

### üìÅ scripts/
- **sql/create_sample_table.sql** ‚Üí Script SQL para criar tabela de exemplo e inserir dados.  
- **powershell/install_self_hosted_ir.ps1** ‚Üí Script PowerShell para instalar o Self-hosted IR.  

### üìÅ logs/
- **samples/run_metadata_example.json** ‚Üí Exemplo de log de execu√ß√£o de pipeline (metadata: tempo, status, registros copiados).  

---

##  Como Executar o Projeto

1. **Prepara√ß√£o no Azure**
   - Crie um **Resource Group**.  
   - Crie um **Storage Account** com **Data Lake Gen2** habilitado.  
   - Crie um **Data Factory**.  

2. **Instala√ß√£o do Self-hosted IR**
   - Siga o guia em [`docs/guia_instalacao_ir.md`](docs/guia_instalacao_ir.md).  
   - Instale o IR na m√°quina local e registre com a chave do ADF.  

3. **Configura√ß√£o no ADF**
   - Importe os **Linked Services** (`LS_SQL_OnPrem.json`, `LS_ADLS.json`, `LS_KeyVault.json`).  
   - Importe os **Datasets** (`DS_SQL_OnPrem_<Tabela>.json`, `DS_ADLS_RAW_TXT.json`, `DS_ADLS_BRONZE_TXT.json`).  
   - Importe o **Pipeline** (`pl_redundancia_sql_to_datalake.json`).  
   - Configure o **Trigger** (`tr_daily_0200_brt.json`).  

4. **Execu√ß√£o**
   - Execute manualmente o pipeline ou aguarde o trigger di√°rio.  
   - Verifique os arquivos gerados no ADLS (`raw` e `bronze`).  

5. **Processamento com Databricks (opcional)**
   - Configure o cluster com `databricks/configs/cluster_config.json`.  
   - Execute o notebook `bronze_promote_<tabela>.ipynb` para promover dados.  

6. **Valida√ß√£o**
   - Consulte os logs em `logs/samples/run_metadata_example.json`.  
   - Verifique prints em `docs/imagens/` para confirmar configura√ß√£o.  

---

## Prints do Projeto

- Linked Services ‚Üí `docs/imagens/adf_linked_services.png`  
- Datasets ‚Üí `docs/imagens/adf_datasets.png`  
- Arquitetura ‚Üí `docs/arquitetura_azure.png`  

---

##  Boas Pr√°ticas
- **Seguran√ßa:** Armazene segredos no Key Vault.  
- **Governan√ßa:** Organize dados em camadas (`raw`, `bronze`).  
- **Performance:** Ajuste paralelismo no Copy Activity.  
- **Custos:** Use redund√¢ncia LRS em conta de estudante.  
- **Logs:** Sempre registre metadata de execu√ß√£o.  

---

## Licen√ßa
Este projeto est√° licenciado sob a licen√ßa MIT.  
Sinta-se livre para usar e adaptar em seus pr√≥prios projetos.

---

## Conclus√£o
Este projeto demonstra uma solu√ß√£o pr√°tica e did√°tica para **redund√¢ncia de arquivos na Azure**, integrando ambientes locais e nuvem. 

Com pipelines bem estruturados, camadas de dados e documenta√ß√£o completa, voc√™ ter√° um portf√≥lio s√≥lido para apresentar em entrevistas e projetos reais.

---
**Autor:**
  Sergio Santos 

---
